# -*- coding: utf-8 -*-
"""TUMOR_PREDICTOR_TESTING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d-TFv-jzbqvRimLJcLnlK96qZ9SFDrv9
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

import os
from tensorflow.keras.models import load_model


model = load_model('tumor_pred3.h5')

#predicting the model
import os
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2

model =tf.keras.models.load_model('tumor_pred3.h5')

folder_path ='/content/drive/My Drive/TFG/prediction'
images= os.listdir(folder_path)
n_images =len(images)
selected_images =random.sample(images, 20)

fig, axs= plt.subplots(nrows=4,ncols=5,figsize=(15, 10))
axs= axs.ravel()
for i in range(20):
    img=Image.open(os.path.join(folder_path,selected_images[i]))
    img =cv2.resize(np.array(img),(150,150))
    img =cv2.cvtColor(img,cv2.COLOR_RGBA2RGB)
    img= np.expand_dims(img,axis=0)

    prediction =model.predict(img)
    if prediction>0.5:
        label ='Tumor'
        color ='red'
    else:
        label ='No Tumor'
        color ='green'

    axs[i].imshow(cv2.cvtColor(cv2.imread(os.path.join(folder_path, selected_images[i])),cv2.COLOR_BGR2RGB))
    axs[i].set_title(label,color=color)
    axs[i].axis('off')
    axs[i].text(0,-15,selected_images[i],fontsize=8)

plt.tight_layout()
plt.show()

test_dir ='/content/drive/My Drive/TFG/DATA/tumor 2/Testing'

from tensorflow.keras import layers

#testing the model
batch_size= 32
target_size =(150,150)

test_data =tf.keras.preprocessing.image_dataset_from_directory(test_dir,image_size=target_size,batch_size=batch_size,)

test_loss, test_acc = model.evaluate(test_data)
print('Test accuracy:', test_acc)

import pandas as pd
import numpy as np
import sklearn.metrics as metrics
#predictions
y_pred= np.array([])
y_true = np.array([])
for images, labels in test_data:
    preds = model.predict(images)
    y_pred = np.concatenate([y_pred, np.round(preds).flatten()])
    y_true = np.concatenate([y_true, labels.numpy().flatten()])

#confusion matrix
cm = metrics.confusion_matrix(y_true, y_pred)

cm_df = pd.DataFrame(cm, columns=['Predicted Negative', 'Predicted Positive'], index=['Actual Negative', 'Actual Positive'])
print(cm_df)

cm_df

#classification report
report= metrics.classification_report(y_true, y_pred, labels=[0,1])
print(report)

# Compute the precision, recall, and f1-score
precision = metrics.precision_score(y_true, y_pred)
recall= metrics.recall_score(y_true, y_pred)
f1_score =metrics.f1_score(y_true, y_pred)
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-score: {f1_score:.2f}")

model.summary()

!jupyter nbconvert --to html TUMOR_PREDICTOR_TESTING.ipynb