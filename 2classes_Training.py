# -*- coding: utf-8 -*-
"""TUMOR_PREDICTOR_FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V8PJfJiY01QPk6uHeVPQTAmjYMecGXqF
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import layers
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

train_directory ='/content/drive/My Drive/TFG/DATA/tumor 2/Training'
test_directory ='/content/drive/My Drive/TFG/DATA/tumor 2/Testing'

#Taking the dataset
image_size =(150, 150)
batch_size =16

train_ds =tf.keras.preprocessing.image_dataset_from_directory(train_directory, image_size=image_size, batch_size=batch_size, validation_split=0.2, subset='training', seed=123)

val_ds =tf.keras.preprocessing.image_dataset_from_directory(train_directory, image_size=image_size, batch_size=batch_size, validation_split=0.2, subset='validation', seed=123)

test_ds =tf.keras.preprocessing.image_dataset_from_directory(test_directory,image_size=image_size, batch_size=batch_size,)

#Plot of the dataset
import matplotlib.pyplot as plt

train_img,train_lb =next(iter(train_ds.take(6)))
val_img,val_lb=next(iter(val_ds.take(6)))
test_img,test_lb =next(iter(test_ds.take(6)))

class_names =train_ds.class_names

fig, axs =plt.subplots(3,4,figsize=(15,8))
for i in range(6):
    axs[0,i].imshow(train_img[i].numpy().astype("uint8"))
    axs[0,i].set_title(class_names[train_lb[i]])
    axs[0,i].axis("off")
    axs[1,i].imshow(val_img[i].numpy().astype("uint8"))
    axs[1,i].set_title(class_names[val_lb[i]])
    axs[1,i].axis("off")
    axs[2,i].imshow(test_img[i].numpy().astype("uint8"))
    axs[2,i].set_title(class_names[test_lb[i]])
    axs[2,i].axis("off")
plt.show()

# pie chart

train_size =len(train_ds.file_paths)
val_size =len(val_ds.file_paths)
test_size =len(test_ds.file_paths)
total_size =train_size +val_size+ test_size

train_percent =train_size /total_size *100
val_percent =val_size/total_size*100
test_percent =test_size /total_size *100

labels =["Training","Validation","Testing"]
sizes =[train_percent,val_percent,test_percent]
colors=["lightblue","lightgreen","yellow"]
fig,ax= plt.subplots()
ax.pie(sizes,labels=labels,colors=colors,autopct="%1.1f%%",startangle=90)
ax.axis("equal")
plt.title("Dataset")
plt.show()

#Model 2
model = tf.keras.Sequential([
    layers.experimental.preprocessing.Rescaling(1./255),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(512,activation='relu'),
    layers.Dense(1,activation='sigmoid')
])
model.compile(loss='binary_crossentropy',optimizer='adam',metrics= ['accuracy'])

history =model.fit(train_ds,validation_data=val_ds,epochs=10)

model.summary()

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.utils import normalize

tf.keras.utils.plot_model(model,
                          to_file= "model.png",
                          show_shapes =True,
                          expand_nested =True)

# plot the accuracy curves
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'],loc ='upper left')
plt.show()

# plot the loss curves
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'],loc= 'upper left')
plt.show()

test_loss, test_acc =model.evaluate(test_ds)
print('Test accuracy:',test_acc)

#second dataset
train_directory2= '/content/drive/My Drive/TFG/DATA/tumor'
batch_size =32
target_size =(150, 150)

train_data2 =tf.keras.preprocessing.image_dataset_from_directory(train_directory2,validation_split=0.2,subset="training",seed=164,image_size=target_size,batch_size=batch_size,)

val_data2= tf.keras.preprocessing.image_dataset_from_directory(train_directory2,validation_split=0.2,subset="validation",seed=164,image_size=target_size,batch_size=batch_size,)

import matplotlib.pyplot as plt

train_images2, train_labels2 =next(iter(train_data2.take(6)))
val_images2, val_labels2=next(iter(val_data2.take(6)))

class_names =train_data2.class_names

fig, axs= plt.subplots(2,6,figsize=(15, 8))
for i in range(6):
    axs[0,i].imshow(train_images2[i].numpy().astype("uint8"))
    axs[0,i].set_title(class_names[train_labels2[i]])
    axs[0,i].axis("off")
    axs[1,i].imshow(val_images2[i].numpy().astype("uint8"))
    axs[1,i].set_title(class_names[val_labels2[i]])
    axs[1,i].axis("off")
plt.show()

history2 = model.fit(train_data2, epochs=10, validation_data=val_data2)

#accuracy curves
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'],loc ='upper left')
plt.show()

# loss curves
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'],loc= 'upper left')
plt.show()

model.save('/content/drive/My Drive/TFG/DATA/tumor_pred3.h5')

model.save('tumor_pred3.h5')

model.save_weights('/content/drive/My Drive/TFG/DATA/tumor_pred3_weights.h5')

!jupyter nbconvert --to html TUMOR_PREDICTOR_FINAL.ipynb