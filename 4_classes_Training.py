# -*- coding: utf-8 -*-
"""4_CLASSES_TUMOR_PRED.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uf4w66OkoGTByxYd3fSIcPtbdMkd_bB9
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
import os
import re
import cv2

from google.colab import drive
drive.mount('/content/drive')

train_directory='/content/drive/My Drive/TFG/NEW TUMOR/DATA/archive/Training'
test_directory='/content/drive/My Drive/TFG/NEW TUMOR/DATA/archive/Testing'

image_size = (150, 150)
batch_size = 16

train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_directory, image_size=image_size, batch_size=batch_size, validation_split=0.2, subset='training', seed=123)

val_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_directory, image_size=image_size, batch_size=batch_size, validation_split=0.2, subset='validation', seed=123)

test_dataset = tf.keras.preprocessing.image_dataset_from_directory(test_directory,image_size=image_size, batch_size=batch_size,)

class_names =train_dataset.class_names

img_dictionary ={}

for images, labels in train_dataset:
    shuffled_indices =np.random.permutation(len(images))
    for i in shuffled_indices:
        image, label =images[i],labels[i]
        label_name =class_names[label]
        if label_name not in img_dictionary:
            img_dictionary[label_name] =image
            break
    if len(img_dictionary) ==len(class_names):
        break

# Plot
fig, axs =plt.subplots(1, len(class_names), figsize =(15, 15))
for i, class_name in enumerate(class_names):
    axs[i].imshow(img_dictionary[class_name].numpy().astype("uint8"))
    axs[i].set_title(class_name)
    axs[i].axis("off")
plt.show()

#Pie-Chart
train_size =len(train_dataset.file_paths)
val_size =len(val_dataset.file_paths)
test_size =len(test_dataset.file_paths)
total_size =train_size +val_size +test_size

train_percent =train_size/total_size *100
val_percent =val_size/total_size *100
test_percent =test_size/total_size *100

labels =["Training", "Validation", "Testing"]
sizes =[train_percent, val_percent, test_percent]
colors =["lightblue", "lightgreen", "yellow"]
fig, ax =plt.subplots()
ax.pie(sizes, labels=labels, colors=colors, autopct="%1.1f%%", startangle=90)
ax.axis("equal")
plt.title("Dataset")
plt.show()

#Model 1 creation

from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Rescaling, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras import regularizers

input_shape = (150, 150, 3)

model = tf.keras.Sequential([
    tf.keras.layers.Rescaling(scale=1./255, input_shape=input_shape),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(4, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_dataset,
                    validation_data=val_dataset,
                    epochs=30)

model.summary()

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.utils import normalize

tf.keras.utils.plot_model(model,
                          to_file= "model.png",
                          show_shapes =True,
                          expand_nested= True)

#Accuracy curves
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'],loc= 'upper left')
plt.show()

#Loss curves
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'],loc= 'upper left')
plt.show()

test_loss,test_acc =model.evaluate(test_dataset)
print('Test accuracy:',test_acc)

model.save('4classes_tumor_pred.h5')

model.save_weights('/content/drive/My Drive/TFG/DATA/4classes_tumor_pred_weights.h5')

model.save('/content/drive/My Drive/TFG/DATA/4classes_tumor_pred.h5')

model.save_weights('4classes_tumor_pred_weights.h5')

!jupyter nbconvert --to html 4_CLASSES_TUMOR_PRED-2.ipynb

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator


# Create an ImageDataGenerator object for data augmentation
data_augmentation = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Create a generator for the images in the training directory with data augmentation
train_generator = data_augmentation.flow_from_directory(
    train_directory,
    target_size=(150, 150),
    batch_size=16,
    class_mode='categorical',
    shuffle=True
)

# Use the generator for training the model
model.fit(train_generator, validation_data=val_dataset, epochs=10)